{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from data_loader import Preprocess\n",
    "from model import TextGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'raw_text': 'raw_text.txt', 'train_file': 'train_data.tsv', 'test_file': 'test_data.tsv',\n",
    "          'embedding': 'embedding.fasttext', 'batch_size': 1, 'epoch': 10000, 'max_seq_len': 5,\n",
    "          'embedding_size': 256, 'plt_frq': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 28461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 2329.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.tsv processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 3102.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data.tsv processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "processor = Preprocess(raw_text = params['raw_text'], max_seq_len=params['max_seq_len'])\n",
    "processor.process(params['train_file'], mode='train')\n",
    "processor.process(params['test_file'], mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if params['embedding']:\n",
    "#     processor.load_embedding(params['embedding'], params['embedding_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['vocab_size'] = processor.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gan = TextGAN(vocabulary=params['vocab_size'], max_seq_len=params['max_seq_len'],\n",
    "                embedding_size=params['embedding_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gan.build_gan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print('\\nGENERATOR: ')\n",
    "# text_gan.generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print('\\nDISCRIMINATOR: ')\n",
    "# text_gan.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<tf.Tensor 'sentence_input:0' shape=(?, 5, 28461) dtype=float32>,\n",
       "  <tf.Tensor 'paraphrase_input:0' shape=(?, 5, 28461) dtype=float32>],\n",
       " [<tf.Tensor 'dense_1/Softmax:0' shape=(?, 2) dtype=float32>])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_gan.discriminator.inputs, text_gan.discriminator.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<tf.Tensor 'sentence_input_1:0' shape=(?, 5, 28461) dtype=float32>],\n",
       " [<tf.Tensor 'dense_2/truediv:0' shape=(?, 5, 28461) dtype=float32>])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_gan.generator.inputs, text_gan.generator.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(losses):\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        plt.figure(figsize=(10,8))\n",
    "        plt.plot(losses[\"d_loss\"], label='discriminitive loss')\n",
    "        plt.plot(losses[\"d_acc\"], label='discriminitive accuracy')\n",
    "        \n",
    "        plt.plot(losses[\"g_loss\"], label='generative loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "def plot_gen(epoch=1):\n",
    "    sentences, _ = processor.posotive_batch(params['batch_size'])\n",
    "    output = text_gan.generator.predict(sentences)\n",
    "    generated_paraphrases = output[1]\n",
    "    \n",
    "    with open('generated/paraphrases_{}.txt'.format(epoch), 'w') as f:\n",
    "        for i in range(len(sentences)):\n",
    "            original_sentence = processor.convert_to_sentence(sentences[i])\n",
    "            generated_paraphrase = processor.convert_to_sentence(np.argmax(generated_paraphrases[i], axis=2))\n",
    "            \n",
    "            f.write('{} | {}\\n'.format(original_sentence, generated_paraphrase))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {'d_loss': [], 'g_loss': [], 'd_acc': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(batch_size, mode='real'):\n",
    "    label = []\n",
    "    for _ in range(batch_size):\n",
    "        if mode == 'real':\n",
    "            label.append([1, 0])\n",
    "        else:\n",
    "            label.append([0, 1])\n",
    "            \n",
    "    return np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:478: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(params['epoch']):\n",
    "    sentence, paraphrase = processor.positive_batch(params['batch_size'])\n",
    "    \n",
    "    gen_sentences = text_gan.generator.predict(sentence)\n",
    "    \n",
    "    real_input = [sentence, paraphrase]\n",
    "    fake_input = [sentence, gen_sentences]\n",
    "    \n",
    "    d_loss_real = text_gan.discriminator.train_on_batch(real_input, get_label(len(real_input[0]), mode='real'))\n",
    "    print('Real Trained')\n",
    "    d_loss_fake = text_gan.discriminator.train_on_batch(fake_input, get_label(len(fake_input[0]), mode='fake'))\n",
    "    print('Fake Trained')\n",
    "    \n",
    "    d_loss = 0.5*np.add(d_loss_real, d_loss_fake)\n",
    "    losses['d_loss'].append(d_loss[0])\n",
    "    losses['d_acc'].append(d_loss[1])\n",
    "    \n",
    "    # Generator\n",
    "    sentence, _ = processor.positive_batch(params['batch_size'])\n",
    "    g_loss = text_gan.text_gan.train_on_batch(sentence, get_label(len(sentence), mode='real'))\n",
    "    losses['g_loss'].append(g_loss)\n",
    "    \n",
    "    if epoch%params['plt_frq'] == params['plt_frq'] - 1:\n",
    "        plot_loss(losses)\n",
    "        save_gen(epoch=epoch)\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
